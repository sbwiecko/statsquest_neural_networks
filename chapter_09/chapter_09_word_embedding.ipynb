{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7cf0aedd-9400-4ce1-8885-d800f997cb6b",
      "metadata": {
        "id": "7cf0aedd-9400-4ce1-8885-d800f997cb6b"
      },
      "source": [
        "# Chapter 9 -- Word Embedding\n",
        "\n",
        "## Introduction\n",
        "\n",
        "In this tutorial, we will use [PyTorch](https://pytorch.org/) and [Lightning](https://www.lightning.ai/) to create and optimize word embeddings using the incredibly simple network seen below.\n",
        "\n",
        "<img src=\"./images/word_embedding_network.png\" alt=\"A simple word embedding network\" style=\"width: 600px;\">\n",
        "\n",
        "This simple network created word embeddings that made two fake movie titles, *Troll 2* and *Gymkata*, cluster together because they were used in similar contexts.\n",
        "\n",
        "<img src=\"./images/trained_embedding_graph.png\" alt=\"A graph of the trained word embeddings\" style=\"width: 600px;\">\n",
        "\n",
        "The training data consists of two phrases, where, for the sake of this demonstration, *Troll 2* is considered a single word.\n",
        "\n",
        "1. \"Troll 2 is great!\"\n",
        "2. \"Gymkata is great!\"\n",
        "\n",
        "In this tutorial, we will:\n",
        "\n",
        "- Build and train a Word Embedding Unit from scratch\n",
        "- Build and train a Word Embedding Unit using `nn.Linear()`\n",
        "- Use `nn.Embedding()` to load and use pre-trained Word Embeddings\n",
        "- Build and train a Word Embedding Unit using `nn.Embedding()` and `nn.Linear()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2e6b9647-24a8-4c13-9665-a036d9a8e121",
      "metadata": {
        "id": "2e6b9647-24a8-4c13-9665-a036d9a8e121",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torch.optim import Adam\n",
        "from torch.distributions.uniform import Uniform\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "import lightning as L\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b08f3bd1-2796-4f93-b13b-eaa2bdda3467",
      "metadata": {
        "id": "b08f3bd1-2796-4f93-b13b-eaa2bdda3467"
      },
      "source": [
        "## Create the datasets\n",
        "\n",
        "Now let's create our training data from two phrases, *Troll 2 is great* and *Gymkata is great*, which gives us a simple 4 word, or token, vocabulary: *Troll 2*, *is*, *great*, *Gymkata*. Our training data consists of two parts: `inputs`, the inputs to the neural network, and `labels`, the expected outputs from the neural networks.\n",
        "\n",
        "The idea is to have each token in a phrase predict the token that follows. For example, using **one-hot-encoding** to represent each token, since *Troll 2* is the first token in our vocalbuary, we will encode the `input` for *Troll 2* with `[1., 0., 0., 0.]`. And since *Troll 2* predicts the second token, *is*, which is the second token in our vocabulary, we will encode the `label` for *Troll 2* with `[0., 1., 0., 0.]`. Likewise, we can encode the `inputs` and `labels` for *is*, *great* and *Gymkata*.\n",
        "\n",
        "_NOTE: Gymkata predicts the second token, *is*, so it's label is `[0., 1., 0., 0.]`._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a7cb3602-b0d5-457c-a5da-97cd3d3f9efa",
      "metadata": {
        "id": "a7cb3602-b0d5-457c-a5da-97cd3d3f9efa",
        "tags": []
      },
      "outputs": [],
      "source": [
        "inputs = torch.tensor([\n",
        "    [1., 0., 0., 0.],  # one-hot-encoding for Troll 2...\n",
        "    [0., 1., 0., 0.],  # ...is\n",
        "    [0., 0., 1., 0.],  # ...great\n",
        "    [0., 0., 0., 1.]]) # ...Gymkata\n",
        "\n",
        "labels = torch.tensor([\n",
        "    [0., 1., 0., 0.],  # \"Troll 2\" is followed by \"is\"\n",
        "    [0., 0., 1., 0.],  # \"is\" is followed by \"great\"\n",
        "    [0., 0., 0., 1.],  # \"great\" isn't followed by anything, but we'll pretend it was followed by \"Gymkata\"\n",
        "    [0., 1., 0., 0.]]) # \"Gymkata\", just like \"Troll 2\", is followed by \"is\"."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9168948f-5e25-48ad-b775-ef04463d9a3a",
      "metadata": {
        "id": "9168948f-5e25-48ad-b775-ef04463d9a3a"
      },
      "source": [
        "Now that we have created the data that we want to train the embeddings with, we'll store it in a `DataLoader`. Since our dataset is so small, using a `DataLoader` is a little bit of an overkill, but it it's easy to do, and it will allow us to easily scale up to a much larger vocabulary when the time comes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "79749df5-3328-4d37-8a85-3fa8df641549",
      "metadata": {
        "id": "79749df5-3328-4d37-8a85-3fa8df641549",
        "tags": []
      },
      "outputs": [],
      "source": [
        "dataset = TensorDataset(inputs, labels)\n",
        "dataloader = DataLoader(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df333b81-aab6-4fed-b593-33439f05d74d",
      "metadata": {
        "id": "df333b81-aab6-4fed-b593-33439f05d74d"
      },
      "source": [
        "## Build and train a Word Embedding Unit from scratch\n",
        "\n",
        "Now that we have the data and `DataLoader` all worked out, let's create the `class` that will create the word embeddings for each token in the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e72b990a-3d31-4437-a995-f926c8cd4d61",
      "metadata": {
        "id": "e72b990a-3d31-4437-a995-f926c8cd4d61"
      },
      "outputs": [],
      "source": [
        "class WordEmbeddingFromScratch(L.LightningModule):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super().__init__()\n",
        "        L.seed_everything(seed=42)\n",
        "\n",
        "        # We're initializing the weights using values from a uniform distribtion\n",
        "        # that goes from -0.5 to 0.5 (notated as U(-0.5, 0.5). This is because of \n",
        "        # how nn.Linear() initializes weights; nn.Linear() uses U(-sqrt(k), sqrt(k)), \n",
        "        # where k=1/in_features. In our case, we have 4 inputs, so k=1/4 = 0.25. \n",
        "        # And the sqrt(0.25) = 0.5. Thus, nn.Linear() would use U(-0.5, 0.5) to \n",
        "        # initialize the weights, so that's what we'll do here as well.\n",
        "\n",
        "        min_value = -0.5\n",
        "        max_value = 0.5\n",
        "\n",
        "        # Now we initialize the weights that feed 4 inputs (one for each unique word)\n",
        "        # into the 2 nodes in the hidden layer (top and bottom nodes). Because we want \n",
        "        # words (or tokens) that are used in the same context to have similar weights, \n",
        "        # we are excluding bias terms from the connections from the inputs to the nodes \n",
        "        # in the hidden layer (alternatively, you could think that we set the bias \n",
        "        # terms to 0 and are not going to optimize them). We're using nn.Parameter() \n",
        "        # here instead of torch.tensor() because we want to easily print out the \n",
        "        # parameters before and after training. Parameters are just tensors that are \n",
        "        # added to model's parameter list.\n",
        "\n",
        "        self.input1_w1 = nn.Parameter(Uniform(min_value, max_value).sample())\n",
        "        self.input1_w2 = nn.Parameter(Uniform(min_value, max_value).sample())\n",
        "\n",
        "        self.input2_w1 = nn.Parameter(Uniform(min_value, max_value).sample())\n",
        "        self.input2_w2 = nn.Parameter(Uniform(min_value, max_value).sample())\n",
        "\n",
        "        self.input3_w1 = nn.Parameter(Uniform(min_value, max_value).sample())\n",
        "        self.input3_w2 = nn.Parameter(Uniform(min_value, max_value).sample())\n",
        "\n",
        "        self.input4_w1 = nn.Parameter(Uniform(min_value, max_value).sample())\n",
        "        self.input4_w2 = nn.Parameter(Uniform(min_value, max_value).sample())\n",
        "\n",
        "        # Now we initialize the weights that come out of the hidden layer to \n",
        "        # \"output\". Again, we are excluding bias terms. This time, we exclude \n",
        "        # them simply because we do not need them.\n",
        "        self.output1_w1 = nn.Parameter(Uniform(min_value, max_value).sample())\n",
        "        self.output1_w2 = nn.Parameter(Uniform(min_value, max_value).sample())\n",
        "\n",
        "        self.output2_w1 = nn.Parameter(Uniform(min_value, max_value).sample())\n",
        "        self.output2_w2 = nn.Parameter(Uniform(min_value, max_value).sample())\n",
        "\n",
        "        self.output3_w1 = nn.Parameter(Uniform(min_value, max_value).sample())\n",
        "        self.output3_w2 = nn.Parameter(Uniform(min_value, max_value).sample())\n",
        "\n",
        "        self.output4_w1 = nn.Parameter(Uniform(min_value, max_value).sample())\n",
        "        self.output4_w2 = nn.Parameter(Uniform(min_value, max_value).sample())\n",
        "\n",
        "        # For the loss function, we'll use CrossEntropyLoss, which we'll use in \n",
        "        # training_step(). The nn.CrossEntropyLoss automatically applies softmax \n",
        "        # for us, so we don't need to import it.\n",
        "        self.loss = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "        # The input is delivered inside of a list, like this\n",
        "        #   [[1., 0., 0., 0.]]\n",
        "        # and it's just easier if we remove the extra pair of brackets:\n",
        "        #   [1., 0., 0., 0.]\n",
        "        input = input[0]\n",
        "\n",
        "        # First, for the top node in the hidden layer, we multiply each input \n",
        "        # by its weight, and then calculate the sum of those products...\n",
        "        inputs_to_top_hidden = (\n",
        "            (input[0] * self.input1_w1)\n",
        "            +\n",
        "            (input[1] * self.input2_w1)\n",
        "            +\n",
        "            (input[2] * self.input3_w1)\n",
        "            +\n",
        "            (input[3] * self.input4_w1)\n",
        "        )\n",
        "\n",
        "        # Then, for the bottom node in the hidden layer,we multiply each input \n",
        "        # by its weight, and then calculate the sum of those products.\n",
        "        inputs_to_bottom_hidden = (\n",
        "            (input[0] * self.input1_w2)\n",
        "            +\n",
        "            (input[1] * self.input2_w2)\n",
        "            +\n",
        "            (input[2] * self.input3_w2)\n",
        "            +\n",
        "            (input[3] * self.input4_w2)\n",
        "        )\n",
        "\n",
        "        # Now, in theory, we could run inputs_to_top_hidden and inputs_to_bottom_hidden \n",
        "        # through linear activation functions, but the outputs would be the exact same \n",
        "        # as in the inputs, so we can just skip that step and instead compute the 4 output \n",
        "        # values from the 2 nodes in hidden layer by summing the products of the hidden \n",
        "        # layer values and a pair of weights for each output.\n",
        "        output1 = (\n",
        "            (inputs_to_top_hidden * self.output1_w1)\n",
        "            +\n",
        "            (inputs_to_bottom_hidden * self.output1_w2))\n",
        "        output2 = (\n",
        "            (inputs_to_top_hidden * self.output2_w1)\n",
        "            +\n",
        "            (inputs_to_bottom_hidden * self.output2_w2))\n",
        "        output3 = (\n",
        "            (inputs_to_top_hidden * self.output3_w1)\n",
        "            +\n",
        "            (inputs_to_bottom_hidden * self.output3_w2))\n",
        "        output4 = (\n",
        "            (inputs_to_top_hidden * self.output4_w1)\n",
        "            +\n",
        "            (inputs_to_bottom_hidden * self.output4_w2))\n",
        "\n",
        "        # Now we need to concatenate the 4 output tensors so that we can run them through\n",
        "        # the SoftMax function. However, because they are tensors (and have gradients \n",
        "        # attached to them), we can't just combine them in a simple list like this:\n",
        "        # output_values = [output1, output2, output3, output4]\n",
        "        # THIS WILL NOT WORK because that would strip off the gradients. Instead, we use \n",
        "        # torch.stack(), which retains the gradients.\n",
        "\n",
        "        output_presoftmax = torch.stack([output1, output2, output3, output4])\n",
        "        # The the loss function we are using, nn.CrossEntropyLoss, automatically applies \n",
        "        # softmax for us, so we need to do that ourselves. If we want to actually use this \n",
        "        # network to predict the next word (instead of just using it for the Word Embedding \n",
        "        # values), then we'll need to apply the softmax() function ourselves (or just look \n",
        "        # to see what output value is largest).\n",
        "\n",
        "        return(output_presoftmax)\n",
        "\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # configure_optimizers() configures the optimizer we want to use for backpropagation.\n",
        "\n",
        "        return Adam(self.parameters(), lr=0.1)\n",
        "\n",
        "\n",
        "    def training_step(self, batch):\n",
        "        # training_step() takes a step of gradient descent.\n",
        "\n",
        "        input_i, label_i = batch # collect input\n",
        "        output_i = self.forward(input_i) # run input through the neural network\n",
        "        loss = self.loss(output_i, label_i[0]) ## loss = cross entropy\n",
        "\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5ef5568-5826-4e07-b807-5764060f39ad",
      "metadata": {
        "id": "a5ef5568-5826-4e07-b807-5764060f39ad"
      },
      "source": [
        "Now that we have created our new `class`, `WordEmbeddingFromScratch`, let's create a model and print out the initial parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "819df074-8ece-4808-a2ec-1c4d258a2094",
      "metadata": {
        "id": "819df074-8ece-4808-a2ec-1c4d258a2094",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Seed set to 42\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before optimization, the parameters are:\n",
            "input1_w1 tensor(0.3800)\n",
            "input1_w2 tensor(0.4200)\n",
            "input2_w1 tensor(-0.1200)\n",
            "input2_w2 tensor(0.4600)\n",
            "input3_w1 tensor(-0.1100)\n",
            "input3_w2 tensor(0.1000)\n",
            "input4_w1 tensor(-0.2400)\n",
            "input4_w2 tensor(0.2900)\n",
            "output1_w1 tensor(0.4400)\n",
            "output1_w2 tensor(-0.3700)\n",
            "output2_w1 tensor(0.4300)\n",
            "output2_w2 tensor(0.0900)\n",
            "output3_w1 tensor(0.3700)\n",
            "output3_w2 tensor(0.0700)\n",
            "output4_w1 tensor(0.2400)\n",
            "output4_w2 tensor(-0.0700)\n"
          ]
        }
      ],
      "source": [
        "modelFromScratch = WordEmbeddingFromScratch()\n",
        "\n",
        "print(\"Before optimization, the parameters are:\")\n",
        "for name, param in modelFromScratch.named_parameters():\n",
        "    print(\n",
        "        name,\n",
        "        torch.round(param.data, decimals=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba85af72-311c-4fd4-94ce-caec261d0380",
      "metadata": {
        "id": "ba85af72-311c-4fd4-94ce-caec261d0380"
      },
      "source": [
        "Notice how the weights for **input1** (`w1 = 0.38` and `w2 = 0.42`) and **input4** (`w1 = -0.24` and `w2 = 0.29`) are very different, even though they both represent movie titles (*Troll 2* and *Gymkata*) that are used in the same context. We can visualize how similar, and different, the embeddings are for all four tokens by plotting them on a graph that has the **w1** values, the embedding values that go to the top node in the hidden layer, on the x-axis and the **w2** values, the embedding values that go to the bottom node in the hidden layer, on the y-axis.\n",
        "\n",
        "First, let's organize the data into a Pandas `DataFrame()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "eb225dd9-549d-4521-8f27-54900e20566d",
      "metadata": {
        "id": "eb225dd9-549d-4521-8f27-54900e20566d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data in the DataFrame format:\n",
            "         w1        w2    token   input\n",
            "0  0.382269  0.415004   Troll2  input1\n",
            "1 -0.117136  0.459306       is  input2\n",
            "2 -0.109552  0.100895    great  input3\n",
            "3 -0.243428  0.293641  Gymkata  input4\n"
          ]
        }
      ],
      "source": [
        "data = {\n",
        "    \"w1\": [\n",
        "        modelFromScratch.input1_w1.item(),  # item() pulls out the tensor value as a float\n",
        "        modelFromScratch.input2_w1.item(),\n",
        "        modelFromScratch.input3_w1.item(),\n",
        "        modelFromScratch.input4_w1.item()],\n",
        "    \"w2\": [\n",
        "        modelFromScratch.input1_w2.item(),\n",
        "        modelFromScratch.input2_w2.item(),\n",
        "        modelFromScratch.input3_w2.item(),\n",
        "        modelFromScratch.input4_w2.item()],\n",
        "    \"token\": [\"Troll2\", \"is\", \"great\", \"Gymkata\"],\n",
        "    \"input\": [\"input1\", \"input2\", \"input3\", \"input4\"]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(\"Data in the DataFrame format:\")\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fab0caa9-9108-4ced-92b2-a4a68ae4ebc2",
      "metadata": {
        "id": "fab0caa9-9108-4ced-92b2-a4a68ae4ebc2"
      },
      "source": [
        "Now let's use the dataframe we just created, `df`, and let's draw a scatter plot of the weights, `w1` and `w2`, for each token in the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9dc9ea88-abcc-46d6-b257-a270d1ef5bf9",
      "metadata": {
        "id": "9dc9ea88-abcc-46d6-b257-a270d1ef5bf9"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(4,4))\n",
        "sns.scatterplot(data=df, x=\"w1\", y=\"w2\")\n",
        "\n",
        "# Add the token that each dot represents to the graph\n",
        "# Troll 2\n",
        "plt.text(\n",
        "    df.w1[0], df.w2[0], df.token[0],\n",
        "    horizontalalignment='left',\n",
        "    size='medium',\n",
        "    weight='semibold')\n",
        "\n",
        "# is\n",
        "plt.text(\n",
        "    df.w1[1], df.w2[1], df.token[1],\n",
        "    horizontalalignment='left',\n",
        "    size='medium',\n",
        "    weight='semibold')\n",
        "\n",
        "# great\n",
        "plt.text(\n",
        "    df.w1[2], df.w2[2], df.token[2],\n",
        "    horizontalalignment='left',\n",
        "    size='medium',\n",
        "    weight='semibold')\n",
        "\n",
        "# Gymkata\n",
        "plt.text(\n",
        "    df.w1[3], df.w2[3], df.token[3],\n",
        "    horizontalalignment='left',\n",
        "    size='medium',\n",
        "    weight='semibold');"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1728efe-638f-4057-a581-ba1871e338c6",
      "metadata": {
        "id": "f1728efe-638f-4057-a581-ba1871e338c6"
      },
      "source": [
        "In the graph we can see that the weights for *Troll 2* (representing **input1**) and *Gymkata* (representing **input4**) are no more similar to each other than the other inputs. However, by training this neural network, we hope that those weights will become similar. So lets create a `Trainer` and train the embedding network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "bee5f1bc-fcef-4cac-b33e-1225ec246f2d",
      "metadata": {
        "id": "bee5f1bc-fcef-4cac-b33e-1225ec246f2d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "\n",
            "  | Name         | Type             | Params | Mode \n",
            "----------------------------------------------------------\n",
            "0 | loss         | CrossEntropyLoss | 0      | train\n",
            "  | other params | n/a              | 16     | n/a  \n",
            "----------------------------------------------------------\n",
            "16        Trainable params\n",
            "0         Non-trainable params\n",
            "16        Total params\n",
            "0.000     Total estimated model params size (MB)\n",
            "1         Modules in train mode\n",
            "0         Modules in eval mode\n",
            "c:\\Users\\SÃ©bastien\\Documents\\data_science\\machine_learning\\statsquest_neural_networks\\.env\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "c:\\Users\\SÃ©bastien\\Documents\\data_science\\machine_learning\\statsquest_neural_networks\\.env\\Lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:310: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "839d681c6fd040b4a7b58bd8207fbd6b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
          ]
        }
      ],
      "source": [
        "trainer = L.Trainer(max_epochs=100)\n",
        "trainer.fit(modelFromScratch, train_dataloaders=dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44c39ac0-9583-4326-9461-9977ed81e78c",
      "metadata": {
        "id": "44c39ac0-9583-4326-9461-9977ed81e78c"
      },
      "source": [
        "Now, with the trained neural network, let's print out the values for each weight..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "64b1d6a9-b64e-49f7-a133-573f0da0249f",
      "metadata": {
        "id": "64b1d6a9-b64e-49f7-a133-573f0da0249f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After optimization, the parameters are:\n",
            "input1_w1 tensor(2.0200)\n",
            "input1_w2 tensor(1.9400)\n",
            "input2_w1 tensor(-2.1800)\n",
            "input2_w2 tensor(2.3200)\n",
            "input3_w1 tensor(-2.0300)\n",
            "input3_w2 tensor(-2.1600)\n",
            "input4_w1 tensor(1.6900)\n",
            "input4_w2 tensor(1.8900)\n",
            "output1_w1 tensor(1.2600)\n",
            "output1_w2 tensor(-1.7700)\n",
            "output2_w1 tensor(3.0800)\n",
            "output2_w2 tensor(1.3600)\n",
            "output3_w1 tensor(-1.5800)\n",
            "output3_w2 tensor(0.8800)\n",
            "output4_w1 tensor(-1.5700)\n",
            "output4_w2 tensor(-3.2900)\n"
          ]
        }
      ],
      "source": [
        "print(\"After optimization, the parameters are:\")\n",
        "for name, param in modelFromScratch.named_parameters():\n",
        "    print(\n",
        "        name,\n",
        "        torch.round(param.data, decimals=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd9d6e38-3d85-4487-946c-e269ad2abe62",
      "metadata": {
        "id": "bd9d6e38-3d85-4487-946c-e269ad2abe62"
      },
      "source": [
        "After **100** epochs, the weights for **input1** (`w1 = 2.02` and `w2 = 1.94`) are now relatively similar to the weights for **input4** (`w1 = 1.69` and `w2 = 1.89`). Just like before, we can illustrate how similar, and different, the embeddings are for all four tokens by plotting them on a graph that has the **w1** values on the x-axis and the **w2** values on the y-axis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9d379cdb-4f2e-4d02-8f56-a2e2928b76c9",
      "metadata": {
        "id": "9d379cdb-4f2e-4d02-8f56-a2e2928b76c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data 'optimized' in the DataFrame format:\n",
            "         w1        w2    token   input\n",
            "0  2.015867  1.941373   Troll2  input1\n",
            "1 -2.181995  2.318636       is  input2\n",
            "2 -2.028367 -2.161824    great  input3\n",
            "3  1.691295  1.894237  Gymkata  input4\n"
          ]
        }
      ],
      "source": [
        "data_opt = {\n",
        "    \"w1\": [\n",
        "        modelFromScratch.input1_w1.item(),\n",
        "        modelFromScratch.input2_w1.item(),\n",
        "        modelFromScratch.input3_w1.item(),\n",
        "        modelFromScratch.input4_w1.item()],\n",
        "    \"w2\": [\n",
        "        modelFromScratch.input1_w2.item(),\n",
        "        modelFromScratch.input2_w2.item(),\n",
        "        modelFromScratch.input3_w2.item(),\n",
        "        modelFromScratch.input4_w2.item()],\n",
        "    \"token\": [\"Troll2\", \"is\", \"great\", \"Gymkata\"],\n",
        "    \"input\": [\"input1\", \"input2\", \"input3\", \"input4\"]\n",
        "}\n",
        "\n",
        "df_opt = pd.DataFrame(data_opt)\n",
        "\n",
        "print(\"Data 'optimized' in the DataFrame format:\")\n",
        "print(df_opt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57088407-e05e-4fa8-990e-1df8d63c1dc3",
      "metadata": {
        "id": "57088407-e05e-4fa8-990e-1df8d63c1dc3"
      },
      "source": [
        "Then draw the scatterplot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f0eddf08-b972-4530-866e-797ef0dad6cf",
      "metadata": {
        "id": "f0eddf08-b972-4530-866e-797ef0dad6cf"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(4,4))\n",
        "sns.scatterplot(data=df_opt, x=\"w1\", y=\"w2\")\n",
        "\n",
        "# For Troll2 and and Gymkata, we're adding offsets to where to print \n",
        "# the tokens because otherwise they will be so close to each other \n",
        "# that they will overlap and be unreadable.\n",
        "\n",
        "# Troll 2\n",
        "plt.text(\n",
        "    df_opt.w1[0]-.2, df_opt.w2[0]+.1, df_opt.token[0],\n",
        "    horizontalalignment='left',\n",
        "    size='medium',\n",
        "    weight='semibold')\n",
        "\n",
        "# is\n",
        "plt.text(\n",
        "    df_opt.w1[1], df_opt.w2[1], df_opt.token[1],\n",
        "    horizontalalignment='left',\n",
        "    size='medium',\n",
        "    weight='semibold')\n",
        "\n",
        "# great\n",
        "plt.text(\n",
        "    df_opt.w1[2], df_opt.w2[2], df_opt.token[2],\n",
        "    horizontalalignment='left',\n",
        "    size='medium',\n",
        "    weight='semibold')\n",
        "\n",
        "# Gymkata\n",
        "plt.text(\n",
        "    df_opt.w1[3]-.3, df_opt.w2[3]-.3, df_opt.token[3],\n",
        "    horizontalalignment='left',\n",
        "    size='medium',\n",
        "    weight='semibold');"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e9fca6a-21a6-4de4-b9cf-87818bbe3ac7",
      "metadata": {
        "id": "7e9fca6a-21a6-4de4-b9cf-87818bbe3ac7"
      },
      "source": [
        "Therefore, after training the neural network, we see that the weights for *Troll 2* and *Gymkata* are relatively similar compared to the weights for the other tokens. This is because both tokens have the same context.\n",
        "\n",
        "Lastly, we can verify that each token in the vacabulary correctly predicts the token that follows it by running the **one-hot-encoded** input values for each token through the neural network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2445794-e8b6-4c2d-8b96-297544b21384",
      "metadata": {
        "id": "e2445794-e8b6-4c2d-8b96-297544b21384"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction for 'Troll 2': tensor([0., 1., 0., 0.], grad_fn=<RoundBackward0>)\n",
            "Prediction for 'is': tensor([0., 0., 1., 0.], grad_fn=<RoundBackward0>)\n",
            "Prediction for 'great': tensor([0., 0., 0., 1.], grad_fn=<RoundBackward0>)\n",
            "Prediction for 'Gymkata': tensor([0., 1., 0., 0.], grad_fn=<RoundBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# First, let's create a softmax object\n",
        "softmax = nn.Softmax(dim=0)  # dim=0 applies softmax to the only dimension (the list of values)\n",
        "\n",
        "# Note that the forward() method is flattening the input, i.e., input = input[0].\n",
        "# Because we are stacking 4 scalar values, the shape of the output vector \n",
        "# is a 1D tensor with shape (4), i.e., [val1, val2, val3, val4]:\n",
        "# output_presoftmax = torch.stack([output1, output2, output3, output4])\n",
        "\n",
        "# print the predictions for \"Troll 2\"\n",
        "print(\n",
        "    \"Prediction for 'Troll 2':\",\n",
        "    torch.round(\n",
        "        softmax(\n",
        "            modelFromScratch(\n",
        "                torch.tensor(\n",
        "                    [[1., 0., 0., 0.]])))))\n",
        "\n",
        "# print the predictions for \"is\"\n",
        "print(\n",
        "    \"Prediction for 'is':\",\n",
        "    torch.round(\n",
        "        softmax(\n",
        "            modelFromScratch(\n",
        "                torch.tensor(\n",
        "                    [[0., 1., 0., 0.]])))))\n",
        "\n",
        "# print the predictions for \"great\"\n",
        "print(\n",
        "    \"Prediction for 'great':\",\n",
        "    torch.round(\n",
        "        softmax(\n",
        "            modelFromScratch(\n",
        "                torch.tensor(\n",
        "                    [[0., 0., 1., 0.]])))))\n",
        "\n",
        "# print the predictions for \"Gymkata\"\n",
        "print(\n",
        "    \"Prediction for 'Gymkata':\",\n",
        "    torch.round(\n",
        "        softmax(\n",
        "            modelFromScratch(\n",
        "                torch.tensor(\n",
        "                    [[0., 0., 0., 1.]])))))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17bf631d-fb57-4b67-b172-16facae4099f",
      "metadata": {
        "id": "17bf631d-fb57-4b67-b172-16facae4099f"
      },
      "source": [
        "And we see that all tokens correctly predict (give the highest probability to) the token that follows them. In this case, both *Troll 2* and *Gymkata* both correctly predict the second token, **is**, with probability **1.0**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "839e1b56-7043-4ab9-9a23-e2341b35528e",
      "metadata": {
        "id": "839e1b56-7043-4ab9-9a23-e2341b35528e"
      },
      "source": [
        "## Build and train a Word Embedding Unit using `nn.Linear()`\n",
        "\n",
        "Now that we can make a Word Embedding network from scratch, let's simplify the code using `nn.Linear()`. This method will make initialzing the tensors easy and the math we do in the `forward()` step will also be much simpler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "1cb7df2f-c0f7-4abf-93ea-f9a3dd956aed",
      "metadata": {
        "id": "1cb7df2f-c0f7-4abf-93ea-f9a3dd956aed"
      },
      "outputs": [],
      "source": [
        "class WordEmbeddingWithLinear(L.LightningModule):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super().__init__()\n",
        "        L.seed_everything(seed=42)\n",
        "\n",
        "        # In order to initialize weights from the 4 inputs (one for each unique word)\n",
        "        # to the 2 nodes in the hidden layer (top and bottom nodes), we simply make\n",
        "        # one call to nn.Linear() where in_features specifies the number of inputs \n",
        "        # and out_features specifies the number of nodes we are connecting them to. \n",
        "        # Since we don't want to use bias terms, we set bias=False.\n",
        "\n",
        "        self.input_to_hidden = nn.Linear(in_features=4, out_features=2, bias=False)\n",
        "\n",
        "        # Now, in order to connect the 2 nodes in the hidden layer to the 4 outputs, \n",
        "        # we make one call to nn.Linear(), where in_features specifies the number of\n",
        "        # nodes in hidden layer and out_features specifies the number of output \n",
        "        # values we want. And again, we can set bias=False.\n",
        "        \n",
        "        self.hidden_to_output = nn.Linear(in_features=2, out_features=4, bias=False)\n",
        "\n",
        "        # We'll use CrossEntropyLoss in training_step()\n",
        "        self.loss = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "\n",
        "        # Unlike before, where we did all the math by hand, now we can simply pass the \n",
        "        # input values to the weights we created with nn.Linear() between the input and \n",
        "        # the hidden layer and save the result in \"hidden\". Moreover, we don't need to \n",
        "        # strip off the extra brackets from the input. the Linear ojbect knows what to do.\n",
        "\n",
        "        hidden = self.input_to_hidden(input)\n",
        "\n",
        "        # Then we pass \"hidden\" to the weights we created with nn.Linear() between the \n",
        "        # hidden layer and the output.\n",
        "\n",
        "        output_values = self.hidden_to_output(hidden)\n",
        "\n",
        "        return(output_values)\n",
        "\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return Adam(self.parameters(), lr=0.1)\n",
        "\n",
        "\n",
        "    def training_step(self, batch):\n",
        "        input_i, label_i = batch\n",
        "        output_i = self.forward(input_i)\n",
        "        loss = self.loss(output_i, label_i)\n",
        "\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bb2afd6-c1f0-4805-8916-8fb3e92a65c8",
      "metadata": {
        "id": "7bb2afd6-c1f0-4805-8916-8fb3e92a65c8"
      },
      "source": [
        "Now that we have created our new `WordEmbeddingWithLinear` class, let's create a model and print out the initial parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "7c00e9a7-3a31-4e22-8e78-f7bdb5b0e6de",
      "metadata": {
        "id": "7c00e9a7-3a31-4e22-8e78-f7bdb5b0e6de"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Seed set to 42\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before optimization, the parameters are:\n",
            "input_to_hidden.weight tensor([[ 0.3800,  0.4200, -0.1200,  0.4600],\n",
            "        [-0.1100,  0.1000, -0.2400,  0.2900]])\n",
            "hidden_to_output.weight tensor([[ 0.6200, -0.5200],\n",
            "        [ 0.6100,  0.1300],\n",
            "        [ 0.5200,  0.1000],\n",
            "        [ 0.3400, -0.1000]])\n"
          ]
        }
      ],
      "source": [
        "modelLinear = WordEmbeddingWithLinear()\n",
        "\n",
        "print(\"Before optimization, the parameters are:\")\n",
        "for name, param in modelLinear.named_parameters():\n",
        "    print(name, torch.round(param.data, decimals=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d06f215c-dc33-4dfb-8b5f-1e3b4fb6d4bf",
      "metadata": {
        "id": "d06f215c-dc33-4dfb-8b5f-1e3b4fb6d4bf"
      },
      "source": [
        "We then create a `DataFrame` with the embedding values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "23465b4e-5332-431f-8cc2-9d468939a618",
      "metadata": {
        "id": "23465b4e-5332-431f-8cc2-9d468939a618"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding vectors in DataFrame:\n",
            "         w1        w2    token   input\n",
            "0  0.382269 -0.109552   Troll2  input1\n",
            "1  0.415004  0.100895       is  input2\n",
            "2 -0.117136 -0.243428    great  input3\n",
            "3  0.459306  0.293641  Gymkata  input4\n"
          ]
        }
      ],
      "source": [
        "data_embedding = {\n",
        "    # Unlike before, when we called item() on each individual Weight, \n",
        "    # now that we are using nn.Linear, we access the Weights with \n",
        "    # the `weight` attribute`. We then have to remove the gradients\n",
        "    # associated with each Weight, so we also call .detach(). Lastly, \n",
        "    # we then convert the tensor to a numpy array with  numpy().\n",
        "\n",
        "    # [0] = Weights to top activation function\n",
        "    \"w1\": modelLinear.input_to_hidden.weight.detach()[0].numpy(),\n",
        "    # [1] = Weights to bottom activation function\n",
        "    \"w2\": modelLinear.input_to_hidden.weight.detach()[1].numpy(),\n",
        "    \"token\": [\"Troll2\", \"is\", \"great\", \"Gymkata\"],\n",
        "    \"input\": [\"input1\", \"input2\", \"input3\", \"input4\"]\n",
        "}\n",
        "\n",
        "df_embedding = pd.DataFrame(data_embedding)\n",
        "\n",
        "print(\"Embedding vectors in DataFrame:\")\n",
        "print(df_embedding)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e87ae627-6ed2-4417-a81d-9efd8e4858fc",
      "metadata": {
        "id": "e87ae627-6ed2-4417-a81d-9efd8e4858fc"
      },
      "source": [
        "Finally we draw a scatter plot of the new, initial, unoptimized, embedding values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "2d2b359f-3a3f-4835-84ef-d45600badd21",
      "metadata": {
        "id": "2d2b359f-3a3f-4835-84ef-d45600badd21"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcAAAAFzCAYAAACpe9moAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAKMJJREFUeJzt3Ql0VFW+7/F/SEgChEwECAmTTAEUSC5DBB8EFBuetIriFWmVQUHv6wa8ot0EW4FGvQGbBq6I2qJotxNoA77bIrkNyKgIyCwzKDJJIAKBgCQhOW/9d7+qm0ASEgk17e9nrbMqZ6o6p6pyfrX32fucIMdxHAEAwDLVvL0BAAB4AwEIALASAQgAsBIBCACwEgEIALASAQgAsBIBCACwEgEIALBSiLc3wNcVFRXJsWPHpHbt2hIUFOTtzQGAa6bXPzl37pwkJCRItWr2loMIwKvQ8GvUqJFnPg0A8KDDhw9Lw4YNrX3PCcCr0JKf64sSGRnpic8EAK6rs2fPmh/2ruObrQjAq3BVe2r4EYAAAkmQ5ad17K38BQBUqYMHD5pQ1WHFihXi6whAAAgQFy9elOnTp0u3bt0kOjpawsLCpHHjxtK7d2+ZNm2a+JMVK1a4w1SD9XqgChQAAsCPP/4ot912m2zdutWM16xZU1q1amVae65cuVKWLVsmY8aM8fZm+hS/KwHOmjVLmjZtKuHh4ZKamirr168vc9kFCxZIp06dzC+hWrVqSXJysrz77rse3V4A8ISRI0e6w++JJ54wgbh9+3ZTesrOzpa3337bhKCWqKKiokqsO3PmTDNdj5Vaipw4caK79LV48WITpHoMffDBB+X8+fPywgsvSN26daVBgwYyYcKEcrfr5ZdfNs8THBzsPv6mp6fLjTfeaF6vevXqpjvGkCFD5IcffjDz9fV79erlfo4bbrjBPMfQoUPNuJZy9XgeGxtr1tdtuffee2Xv3r2Ve9McPzJ37lwnNDTUmTNnjrNjxw5nxIgRTnR0tJOVlVXq8suXL3cWLFjg7Ny509m/f78zY8YMJzg42MnMzKzwa+bk5OgNg80jAPii06dPm2ObHqs6dOjgFBYWlrpcUVGR06pVK7OcFDuupaWlmfHHHnvMjE+YMMG9TEREhJOUlOQeb9OmjVOjRg2nWbNm7mmuY+p3333nnqbH37feessJCgoy2/bee++5t0O3MSoqyrnpppuc1q1bm2V0nc6dO5v5s2fPNq/jeq7k5GQnNTXVmTRpkpl/9913O7Vq1TLL6HO49r1hw4bOTz/9VOH3za8CsEuXLs5vfvMb97h+yAkJCU5GRkaFnyMlJcV59tlnK7w8AQjA161bt84dFiNHjnRP16BwTdfh7bffdqZNm+YeP3XqlClAVKtWzYyvWbPmigB0Bdctt9zinqbL6fG3SZMmZnzs2LFXBOC//du/mefVcPrggw9KbO+2bdtKhLQGnms9LawoDVDXNH3e4rQAlJ+f7x5fsmSJe9mlS5dW+H3zmyrQ/Px82bhxozmZ66JXMNDxtWvXXnV9DXst/u/Zs0d69OhR5nJ5eXmmj0zxAQD8RfEruyQlJUmHDh1KzNdqxBo1api/9Zj4ySefmCtetWjRQm655ZYrnu/OO+80j3rqScXExJjl9HWaNGlipmVlZV2x3uuvv26eVxvfDBo0qMS8LVu2SOfOnSUiIsJUbY4YMaLExUeu5vvvvzdVpNo1Tbfj9ttvr9T6Ln4TgFqHXVhYKPXr1y8xXcePHz9e5no5OTnmTQ4NDZV+/fqZuu7ib9blMjIyTP24a+AqMAB8Uc6FfDlwIlc2HzotoXUSzTk29eWXX7qXmTJlisydO7fEehpgAwYMMH+/9957Mn/+fPP34MGDS30dV//nkJB/tpks3h/a1Y9QCxiX0+Oueu2118zx22XNmjXmfN+mTZtMWw4NwjZt2rjn63G+PN9++630799fvvjiCzPesWNHcz6wouv7ZQD+XHqlA/21sWHDBnnxxRdNK6jy+qeMGzfOhKZr0CvAAIAvOXbmJxn54Wa5bdpKuefVL6X/7C3SqONtZt7XX39tGqaUFwSPPPKIedQGLsuXLzdB9vDDD1d5g0Vt3LJ792654447JDc310xft26dOzC1kY42ZCwtfLUVq4s2vHHZvHmzqRFU//3f/22O7WPHjg3sbhBxcXHmF87lRW0dj4+PL3M9LR5r0V7pr4Rdu3aZUl7Pnj1LXV77zegAAL5a8hs7f5us3vc/pSp16eahEnPsWzl9ZL9MmjRJZsyYIc2aNXO3rCxOS03KFSRpaWnuKs6qov0PNWD1lJOGlJbaFi1aJO3bt3cv065dO9OC88SJE1es37x5c9PCs6CgwJzq0urWp59+Wm666SaTBRrwffv2Na9TXi1gQJQAtQpTPzSts3bR+mUd79q1a4WfR9fR83wA4I+yc/OvCD8VXCNSIu6fIr97bpI5VuqxTktfer6vT58+5pychlBpBpdR/XmtNOwWLlxojt96rNZzgbfeequpmtXS4U8//SStW7c21aSXq1OnjulCoaehtKCjJUcNOl1+zpw5pmuEBrgWjj788MOftX1B2hJG/MS8efNM3fGf//xn6dKli/mF89FHH5kPWc8F6oeYmJhoSnhKH7UfoP6S0ND77LPPTP8TfbOHDx9eodfURjB6LlCrQ7kWKABv03N+Wu1Zlk9+3U2SG8dU6LimtH+flhJtvDC231SBqoEDB8rJkydl/Pjx5peAVmlmZma6G8YcOnSoRAsorTf+9a9/LUeOHDG/gvSXg5701ecBAH8UGV693Pm1rzJfTwPpMdTl8ccftzL8/K4E6A2UAAH42jnAUR9ullWlVIP2aBknMwelSFTN0DLX10aArqusDBgwwFydxdUtwjYE4FUQgAB8sRVo+vxtJUJQw2/KgPbSIPrqYcZxzQ+rQAEAIgnRNUxJTxvEnLtYYKo94yJCyy354UoEIAD4IQ07Au/a+E03CAAAqhIBCACwEgEIALASAQgAsBIBCACwEgEIALASAQgAsBIBCACwEgEIALASAQgAsBIBCACwEgEIALASAQgAsBIBCACwEgEIALASAQgAsBIBCACwEgEIALASAQgAsBIBCACwEgEIALASAQgAsBIBCACwEgEIALASAQgAsBIBCACwEgEIALASAQgAsBIBCACwEgEIALASAQgAsBIBCACwEgEIALASAQgAsBIBCACwEgEIALASAQgAsBIBCACwkt8F4KxZs6Rp06YSHh4uqampsn79+jKXnT17tnTv3l1iYmLM0Lt373KXBwDYw68CcN68eTJmzBiZMGGCbNq0STp06CB9+vSREydOlLr8ihUrZNCgQbJ8+XJZu3atNGrUSH7xi1/I0aNHPb7tAADfEuQ4jiN+Qkt8nTt3lldeecWMFxUVmVAbNWqUpKenX3X9wsJCUxLU9QcPHlyh1zx79qxERUVJTk6OREZGXvM+AIC3cVzzsxJgfn6+bNy40VRjulSrVs2Ma+muIi5cuCAFBQUSGxt7HbcUAOAPQsRPZGdnmxJc/fr1S0zX8d27d1foOcaOHSsJCQklQvRyeXl5Zij+SwkAEHj8pgR4rSZPnixz586VhQsXmgY0ZcnIyDBVnq5Bq1gBAIHHbwIwLi5OgoODJSsrq8R0HY+Pjy933alTp5oA/Mc//iHt27cvd9lx48aZ832u4fDhw1Wy/QAA3+I3ARgaGiodO3aUZcuWuadpIxgd79q1a5nrvfTSS/L8889LZmamdOrU6aqvExYWZhq7FB8AAIHHb84BKu0CMWTIEBNkXbp0kRkzZsj58+dl2LBhZr627ExMTDTVmGrKlCkyfvx4+eCDD0zfwePHj5vpERERZgAA2MuvAnDgwIFy8uRJE2oaZsnJyaZk52oYc+jQIdMy1OW1114zrUfvu+++Es+j/QgnTpzo8e0HAPgOv+oH6A30lwEQaDiu+dk5QAAAqhIBCACwEgEIALASAQgAsBIBCACwEgEIALASAQgAsBIBCACwEgEIALASAQgAsBIBCACwEgEIALASAQgAsBIBCACwEgEIALASAQgAsBIBCACwEgEIALASAQgAsBIBCACwEgEIALASAQgAsBIBCACwEgEIALASAQgAsBIBCACwEgEIALASAQgAsBIBCACwEgEIALASAQgAsBIBCACwEgEIALASAQgAsBIBCAAe0rRpUwkKCpKJEyfynvuAEG9vAADYIiUlReLj46Vhw4be3hQQgADgOQsXLuTt9iFUgQKAF6pACwsLZdy4cdKsWTMJDw+X2NhY6dSpk/zxj3/k8/AQAhAAvGDWrFkyefJkOXTokCQlJUmdOnVk+/btsmjRIj4PD+EcIAB4wb59+8zjsGHDZPbs2ebv3Nxc2bVrF5+Hh1ACBAAv+OUvf2mqQ998801JTEyUXr16yQsvvGCqQuEZ1fyx2kDr0bXOPDU1VdavX1/msjt27JABAwa4691nzJjh0W0FgJwL+XLgRK5sPnRaLhU57jekT58+smnTJnnmmWdM69C9e/fKlClT5JZbbjElQVx/flUFOm/ePBkzZoy8/vrrJvw00PRLtGfPHqlXr94Vy1+4cMGcYP7Xf/1XefLJJ72yzQDsdezMTzJ2/jZZvS/bjB/PuWgez10skG3btkndunXlxRdf/Oe848elQYMGkpWVZY5pHTt29Oq228CvSoDTpk2TESNGmDrztm3bmiCsWbOmzJkzp9TlO3fubFpUPfDAAxIWFubx7QVgd8mvePgVt3Rnlrz7/ofSqFEjady4sQm7du3amXl6TGvevLkXttg+fhOA+fn5snHjRundu7d7WrVq1cz42rVrvbptAHC57Nz8UsNPfX/qgtzY8Wbp27evFBUVyTfffCOO48itt94qixcvlujoaN5QD/CbKtDs7GzTb6Z+/folpuv47t27q+x18vLyzOBy9uzZKntuAPY4e7HgimkN/8//1FYl39xNht5/t4e3Cn5ZAvSUjIwMiYqKcg9aRQEAlRUZXr3c+bWvMh/Xn98EYFxcnAQHB5sTxMXpuF5br6rolRlycnLcw+HDh6vsuQHYIy4iVHq0jCt1nk7X+fAuvwnA0NBQc6J42bJl7mlad67jXbt2rbLX0cYykZGRJQYAqKyomqEyeUD7K0JQx6cMaG/mw7v85hyg0i4QQ4YMMdfL69Kli+kGcf78edMqVA0ePNh0KNVqTFfDmZ07d7r/Pnr0qGzZskUiIiKkRYsWXt0XAIEvIbqGzByUYhrEaNcHrfbUkh/h5xv8KgAHDhwoJ0+elPHjx5s+M8nJyZKZmeluGKPX1NOWoS7Hjh0zHUxdpk6daoa0tDRZsWKFV/YBgF007Ag83xTkaNtblElbgWpjGD0fSHUogEDAcc3PzgECAFCVCEAAgJUIQACAlQhAAICVCEAAgJUIQACAlQhAAICVCEAAgJUIQACAlQhAAICVCEAAgJUIQACAlQhAAICVCEAAgJUIQACAlQhAAICVCEAAgJUIQACAlQhAAICVCEAAgJUIQACAlQhAAICVCEAAgJUIQACAlQhAAICVCEAAgJUqHYCfffaZDB8+XH73u9/J7t27S8w7ffq03HrrrVW5fQAAeD8AP/jgA7nrrrvk+PHjsnbtWklJSZH333/fPT8/P19Wrlx5PbYTAIAqFVKZhf/4xz/KtGnTZPTo0Wb8o48+kkceeUQuXrwojz76aNVuGQAAvhKA+/btkzvvvNM9fv/990vdunVNqbCgoEDuueee67GNAAB4NwAjIyMlKytLbrjhBve0Xr16yaeffiq//OUv5ciRI1W/hQAAePscYJcuXWTx4sVXTE9LS5O///3vMmPGjKrcNgAAfCMAn3zySQkPDy91Xs+ePU0IDh48uKq2DQCA6ybIcRynsitpyGnVZ48ePaR58+YSyM6ePStRUVGSk5NjqoABwN9xXLuGjvChoaGSkZEhLVu2lEaNGslDDz0kb775pmkkAwBAwJYAXY4ePSqrVq0yff902Lt3rzRo0CCgGsPwSwlAoOG4VgWXQouJiZE6deqYx+joaAkJCTHdIgAACMgAfOaZZ6Rbt24m/NLT001HeH3UK8Rs3ry56rcSAABfqAKtVq2aKelpq9B7771XWrVqJYGKqgIAgYbj2s/oCO+ipTw957dixQr505/+ZBrFaF9A7QqhQyAHIgAgMFxTIxiXrVu3yvTp082FsYuKiqSwsFACBb+UAAQajmvXUALUzNRSoJYAdVizZo15Q9u3b29KggAABGQjmNjYWElNTTW3R9K+gH/5y18kOztbNm3aZEqC19OsWbOkadOm5oo0ug3r168vd/mPP/5YWrdubZZv166duZ8hAAA/qwT43nvvSffu3T1+ZZR58+bJmDFj5PXXXzfhp9ce7dOnj+zZs0fq1at3xfJffvmlDBo0yHTa14t1a2D379/fBPVNN93k0W0HAATgOUBP0dDr3LmzvPLKK2ZczzfqlWhGjRplumFcbuDAgXL+/HlztwqXm2++WZKTk02IVgR15QACDce1KugI70l6t/mNGzdK7969S3TH0HG9O31pdHrx5ZWWGMtaXuXl5ZkvR/EBABB4/CYA9Ryjti6tX79+iek6rh3wS6PTK7O80upSvfi1a9ASJgAg8PhNAHrKuHHjzJ0fXMPhw4e9vUkAAF9pBOMNcXFxEhwcbO5IX5yOx8fHl7qOTq/M8iosLMwMAIDA5jclQL3aTMeOHWXZsmXuadoIRse7du1a6jo6vfjyasmSJWUuDwCwh9+UAJV2gRgyZIh06tRJunTpYrpBaCvPYcOGuW/Um5iYaM7jqSeeeMJ0zNfLtfXr10/mzp0rX3/9tbzxxhte3hMAgLf5VQBqt4aTJ0/K+PHjTUMW7c6QmZnpbuhy6NAh0zLURe9YoX3/nn32WXMHC+20/8knn9AHEADgX/0AvYH+MgACDcc1PzsHCABAVSIAAQBWIgABAFYiAAEAViIAAQBWIgABAFYiAAEAViIAAQBWIgABAFYiAAEAViIAAQBWIgABAFYiAAEAViIAAQBWIgABAFYiAAEAViIAAQBWIgABAFYiAAEAViIAAQBWIgABAFYiAAEAViIAAQBWIgABAFYiAAEAViIAAQBWIgABAFYiAAEAViIAAQBWIgABAFYiAAEAViIAAQBWIgABAFYiAAEAViIAAQBWIgABAFYiAAEAViIAAQBWIgABAFYiAAHAB6xYsUKCgoLMcPDgQTNt6NChZrxnz57e3ryARAACQAU0bdrUHVBlDRMnTrzu72V6erp07dpV6tWrJ+Hh4dKsWTMZNWqUnDhxgs8xUAPw1KlT8uCDD0pkZKRER0fLo48+Krm5ueWu88Ybb5hfTrqOfjnPnDnjse0FEFhSUlIkNTXVDImJie7pycnJ7ukNGzYssU5+fn6Vb8eUKVNkw4YNUr9+falTp45899138sorr8htt90mRUVFVf56gcxvAlDDb8eOHbJkyRL59NNPZdWqVfLYY4+Vu86FCxekb9++8swzz3hsOwEEpoULF8pXX31lhuHDh18xXUtjI0aMkIcfflh++9vfmhJaUlKSWaawsFD+9Kc/Sdu2bSUsLEyioqLk9ttvl9WrV1d6O37/+9/LDz/8INu3b5dDhw7JgAEDzPRvvvlGtm7dWoV7HPhCxA/s2rVLMjMzza+eTp06mWkzZ86UO+64Q6ZOnSoJCQmlrvfv//7v7rp1APCEjz76SBzHMeFXrdo/yxiPP/64vPXWW+bvFi1amBqtpUuXmmOTPqalpVX4+V944QX338HBwdKtWzeZP3++GddwRYCVANeuXWuqPV3hp3r37m2+XOvWravS18rLy5OzZ8+WGACgMvTHupbQNm3aJAcOHJA5c+aY6U888YTs27dPvv32W2nSpIlcunRJxo8f/7Pf3PPnz8tf//pX8/ctt9xiSpgIsAA8fvy4qU4oLiQkRGJjY828qpSRkWGqJ1xDo0aNqvT5AQS2Xr16SYcOHdwltI0bN5oSofrVr35lHvXYojVY6uuvv/5Zr3Py5Elz3k+rPVu3bi0ff/xxle2DLbwagNqa6Wqtqnbv3u3RbRo3bpzk5OS4h8OHD3v09QH4lpwL+XLgRK5sPnRaDpzMNePl0cYp19uePXvk5ptvNjVg+qjnEhs0aHDdXzfQePUc4FNPPWX6uZRHm/jGx8df0cRXqw60Hl3nVSWtQ6ceHYA6duYnGTt/m6zel+1+Q3q0jJO6FwvKfIP0h3txHTt2NNO0FPjBBx9Ily5dzI/rzz77zMwvfmqnIrQB4D333GOOf/fdd5+8++67pgEO/CwA69ata4ar0T4v2oVBqxL0y6Q+//xz0+RXmx4DQFXTkt7l4adW7cuWqJ1ZFX6e5s2byyOPPGIawfznf/6nLFq0yISXDnoq5w9/+EOltktbj2r3Cg1VbQVavJP8c889J/369avU89nML1qBtmnTxnRn0CbGr7/+uhQUFMjIkSPlgQcecLcAPXr0qKkP1xPC+gtL6flBHfbv32/G9aR07dq1pXHjxub8IQCUJTs3/4rwc/n+1IVKvXF//vOfzXk6bQyjjWK0lkkb8mkDmO7du1fquVx9C7VEuX79+ivOC6LighzX2Vkfp7+WNPT+/ve/m9af2vfl5ZdfloiICDNfLx10ww03yPLly92/iPSqDKX9unr77bevWvXqoq1A9YS1Vlloh3oAdtBzfve8+mWZ8z/5dTdJbhwj/ojjmp8FoLfwRQHspA1fbpu2ssz5y8akSfN6//wB7m84rvlRNwgA8LS4iFDT4KU0Ol3nw78RgABQiqiaoTJ5QPsrQlDHpwxob+bDv/lFIxgA8IaE6Boyc1CKaRBz7mKB1A6vbkp+hF9gIAABoBwadgReYKIKFABgJQIQAGAlAhAAYCUCEABgJQIQAGAlAhAAYCUCEABgJQIQAGAlAhAAYCUCEABgJQIQAGAlAhAAYCUCEABgJQIQAGAlAhAAYCUCEABgJQIQAGAlAhAAYCUCEABgJQIQAGAlAhAAYCUCEABgJQIQAGAlAhAAYCUCEABgJQIQAGAlAhAAYCUCEABgJQIQAGAlAhAAYCUCEABgJQIQAGAlAhAAYCUCEABgJQIQAGAlAhAAYCUCEABgJb8JwFOnTsmDDz4okZGREh0dLY8++qjk5uaWu/yoUaMkKSlJatSoIY0bN5bRo0dLTk6OR7cbAOCb/CYANfx27NghS5YskU8//VRWrVoljz32WJnLHzt2zAxTp06Vb775Rt555x3JzMw0wQkAQJDjOI6vvw27du2Stm3byoYNG6RTp05mmobZHXfcIUeOHJGEhIQKPc/HH38sDz30kJw/f15CQkIqtM7Zs2clKirKlBy19AkA/o7jmh+VANeuXWuqPV3hp3r37i3VqlWTdevWVfh5XCFWXvjl5eWZL0fxAQAQePwiAI8fPy716tUrMU1DLDY21syriOzsbHn++efLrTZVGRkZpsTnGho1anRN2w4A8E1eDcD09HQJCgoqd9i9e/c1v46W4vr162eqUSdOnFjusuPGjTMlRddw+PDha359AIDvqdiJsOvkqaeekqFDh5a7TLNmzSQ+Pl5OnDhRYvqlS5dMS0+dV55z585J3759pXbt2rJw4UKpXr16ucuHhYWZAQAQ2LwagHXr1jXD1XTt2lXOnDkjGzdulI4dO5ppn3/+uRQVFUlqamq5Jb8+ffqYQPuv//ovCQ8Pr9LtBwD4L784B9imTRtTihsxYoSsX79evvjiCxk5cqQ88MAD7hagR48eldatW5v5rvD7xS9+YVp8vvXWW2ZczxfqUFhY6OU9AgBYXQKsjPfff9+E3m233WZafw4YMEBefvll9/yCggLZs2ePXLhwwYxv2rTJ3UK0RYsWJZ7ru+++k6ZNm3p4DwAAvsQv+gF6E/1lAAQajmt+VAUKAEBVIwABAFYiAAEAViIAAQBWIgABAFYiAAEAViIALaP9H/Uaq1e7JioABDoC0Ifl5+d7exMAIGARgB5w+vRpGThwoNSsWVMaN24sr732mvTs2dOUxPRRue5+8dJLL8m9994rERER7ls36V0pnnjiCWnSpImEhoZKw4YNZcyYMe6r3qglS5ZI9+7dzW2jdBm976GOL1682Mw/ePCgef7vv//ejP/hD39wvyYA2MhvLoXmz4YPHy4LFiwwf2sI/va3vy1z2eeee85ctPuGG24wQaalQA3JLVu2mOl6XdS9e/fK9OnTZevWrbJ06VITYjt27DCXftP7F2pA7tu3T9asWSN33XWXfP311yYY9cLhmzdvNs+ZmJholgMAa+ml0FC2nJwcvVScefw59u/fb9bX4emnnzbTdu3a5YSEhJhpaWlpZpprmdatWzunTp0y0y5duuS88847ZnpoaKizd+9eM33Lli3u5ZcuXWqmHTx40Dl9+rT7dfU5ateubZZ59tln3dObNGlipk2YMIGPHbDUtR7XAgVVoNeZlsxc7r//fvOod61o3759qcsPGTJEYmJizN/BwcHuu1toqa1Vq1amtJecnOxe/quvvjKPeXl55t6KWtLT9WJjY829ENWxY8eu4x4CgH+iCvQ6yLmQL9m5+XL2YoH8kPNTpdatX79+qdO1OjQlJeWK6a6w1Dve79+/X0JCQqRdu3amutRV3cntnwDgSgRgFTt25icZO3+brN6XbcYLzuS65+kd6Tt37iy7d++Wbdu2lbr+5Y1SdHmlIfbqq6/Kv/zLv5jxixcvyqJFi8ztoX788UcTfmrSpEkybtw40+hFS5qX03OQSu+TCAA2owq0ikt+xcNPVY+Ol5qtupm/MzIyTCOWTp06mRJdRQwaNMhUl2oAahjedNNNkpSUJNHR0XLffffJmTNnTHWnq0HLhAkTTAlQg1JLg5dzhaLeS1Gfb9iwYVW09wDgXwjAKqTVnsXDzyX2f4+Wmkn/S8Jr1DDn5SZPnixt27Y182rUqFHuc4aFhcnKlStl9OjRpoWntgDVbhUaoi+++KKpMtVS4/z5802g6fk/DUu9gXBcXNwVz/fCCy/IzTffbG4qrK1Dt2/fXoXvAAD4D26IW4U3jtx86LTc8+qXV0y/dPakBNeMkv87uqckN46RAwcOmJKcVmOmp6ebkiEAeAo3xP0nzgFWocjw6qVOv7DnS8lZO09GbewstcJCTP88DT8tvY0aNaoqNwEAUEFUgVahuIhQ6dHyymrH6nWbSEx8Q9m2aYMsW7bMtNzUc2/acT0hIaEqNwEAUEFUgVZxVYG2Ak2fv01WFTsXqKE4ZUB7aRBd/vk+APAEqkD/iSrQKpYQXUNmDkoxDWLOXSyQ2uHVTckwqmbFWn0CADyDALwONOwIPADwbZwDBABYiQAEAFiJAAQAWIkABABYiQAEAFiJAAQAWIkABABYiX6AV+E4jvvKCQAQCFzHM+f/H99sRQBehd6+SOmtiAAg0I5vUVFRYiuuBXoVRUVFcuzYMaldu/YVd2u/1l9gGqqHDx+u0DVGfRH74Bv4HHyDP30OWvI7d+6cuRi/3hvUVpQAr0K/HK67rV8P+o/i6/8sV8M++AY+B9/gL59DlMUlPxd7ox8AYDUCEABgJQLQS8LCwmTChAnm0V+xD76Bz8E3BMLnYBsawQAArEQJEABgJQIQAGAlAhAAYCUCEABgJQLQg06dOiUPPvig6SQbHR0tjz76qOTm5pa7zhtvvCE9e/Y06+iVaM6cOSOeNGvWLGnatKmEh4dLamqqrF+/vtzlP/74Y2ndurVZvl27dvLZZ5+Jt1VmH3bs2CEDBgwwy+v7PWPGDPEFldmH2bNnS/fu3SUmJsYMvXv3vurn5mv7sGDBAunUqZP5P6lVq5YkJyfLu+++K95W2f8Hl7lz55rvU//+/a/7NqISHHhM3759nQ4dOjhfffWVs3r1aqdFixbOoEGDyl1n+vTpTkZGhhn04zp9+rTHtnfu3LlOaGioM2fOHGfHjh3OiBEjnOjoaCcrK6vU5b/44gsnODjYeemll5ydO3c6zz77rFO9enVn+/btjrdUdh/Wr1/vPP30086HH37oxMfHm/ff2yq7D7/61a+cWbNmOZs3b3Z27drlDB061ImKinKOHDni+Ms+LF++3FmwYIH5Hu3fv9+ZMWOG+W5lZmY6/rIPLt99952TmJjodO/e3bn77rs9tr24OgLQQ/QfWQNsw4YN7mmLFy92goKCnKNHj151fT0geDoAu3Tp4vzmN79xjxcWFjoJCQkmjEtz//33O/369SsxLTU11Xn88ccdb6nsPhTXpEkTnwjAa9kHdenSJad27drOX/7yF8df90GlpKSYH1X+tA/63nfr1s158803nSFDhhCAPoYqUA9Zu3atqc7Rah0XrZrSa42uW7dOfE1+fr5s3LjRbKOLbquO676URqcXX1716dOnzOV9cR98TVXsw4ULF6SgoEBiY2PFH/dBf6gvW7ZM9uzZIz169BB/2odJkyZJvXr1zOkO+B4uhu0hx48fN/8IJd78kBBzUNJ5viY7O1sKCwulfv36Jabr+O7du0tdR/ejtOW9tX8/Zx98TVXsw9ixY81V/y//ceLr+5CTkyOJiYmSl5cnwcHB8uqrr8rtt98u/rIPa9askbfeeku2bNnioa1EZVECvEbp6enm5HZ5g78cbBF4Jk+ebBpgLFy40DTc8Cd6CzINjw0bNsiLL74oY8aMkRUrVog/0FsNPfzww6ZBUlxcnLc3B2WgBHiNnnrqKRk6dGi5yzRr1kzi4+PlxIkTJaZfunTJtAzVeb5G/2n1V3dWVlaJ6Tpe1vbq9Mos74v74GuuZR+mTp1qAnDp0qXSvn178bd90CrGFi1amL+1FeiuXbskIyPDtIr29X04cOCAHDx4UO68884S9xZ11fxodW7z5s09sOUoDyXAa1S3bl3T7L+8ITQ0VLp27Wq6MOh5BJfPP//c/FNoc2pfo9vcsWNHc+7FRbdVx3VfSqPTiy+vlixZUubyvrgPvubn7sNLL70kzz//vGRmZpY47+zPn4Ouo9Wh/rAP+n+/fft2U4J1DXfddZf06tXL/K03zoUP8HYrHNu6QWhLtnXr1jlr1qxxWrZsWaIbhDZTT0pKMvNdfvjhB9Ocffbs2aYV6KpVq8z4jz/+6JFm32FhYc4777xjWrE+9thjptn38ePHzfyHH37YSU9PL9ENIiQkxJk6dappfj9hwgSf6AZRmX3Iy8sz768ODRo0MF0i9O99+/b5zT5MnjzZNNf/29/+Zr4/ruHcuXN+sw//8R//4fzjH/9wDhw4YJbX75R+t/T/wF/24XK0AvU9BKAHaWhp4EVERDiRkZHOsGHDShyUtL+Qhpx2eXDRENFplw9vv/22R7Z55syZTuPGjc0BVZuBax9Gl7S0NPNPXdxHH33ktGrVyix/4403OosWLXK8rTL74PoMLh90OX/ZB+2+Udo+6HfJX/bh97//veknGx4e7sTExDhdu3Y1AeRtlf1/KI4A9D3cDgkAYCXOAQIArEQAAgCsRAACAKxEAAIArEQAAgCsRAACAKxEAAIArEQAAgCsRAACPubixYvmAuvt2rUzF07u37+/tzcJCEgEIOBj9L5zNWrUkNGjR3vtHn6ADQhAwAM+/fRTiY6ONuGm9I4Aeq9IvZ+ky/Dhw+Whhx6SWrVqyWuvvSYjRozwm9s2Af6IAAQ8oHv37uYmqZs3bzbjK1euNPeYK36DV53mjXvdAbYiAAEPiIqKMjd1dQWePj755JMmEHNzc+Xo0aOyf/9+SUtL4/MAPIQABDxEw02DT29Dtnr1arn33nulTZs2smbNGlP6S0hIkJYtW/J5AB4S4qkXAmyn1Ztz5syRrVu3SvXq1c1dw3WahuLp06cp/QEeRgkQ8PB5wOnTp7vDzhWAOnD+D/AsAhDwkJiYGGnfvr28//777rDr0aOHbNq0Sfbu3VuiBLhz507TUvTUqVOSk5Nj/tYBQNWhChTwIA05DTJXAMbGxkrbtm0lKytLkpKS3Mvdcccd8v3337vHU1JSzKOePwRQNYIc/qMAABaiChQAYCUCEABgJQIQAGAlAhAAYCUCEABgJQIQAGAlAhAAYCUCEABgJQIQAGAlAhAAYCUCEABgJQIQACA2+n8qoHfL1m7wtwAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(4,4))\n",
        "sns.scatterplot(data=df_embedding, x=\"w1\", y=\"w2\")\n",
        "\n",
        "# Add the token that each dot represents to the graph\n",
        "# Troll 2\n",
        "plt.text(\n",
        "    df_embedding.w1[0], df_embedding.w2[0], df_embedding.token[0],\n",
        "    horizontalalignment='left',\n",
        "    size='medium',\n",
        "    weight='semibold')\n",
        "\n",
        "# is\n",
        "plt.text(\n",
        "    df_embedding.w1[1], df_embedding.w2[1], df_embedding.token[1],\n",
        "    horizontalalignment='left',\n",
        "    size='medium',\n",
        "    weight='semibold')\n",
        "\n",
        "# great\n",
        "plt.text(\n",
        "    df_embedding.w1[2], df_embedding.w2[2], df_embedding.token[2],\n",
        "    horizontalalignment='left',\n",
        "    size='medium',\n",
        "    weight='semibold')\n",
        "\n",
        "# Gymkata\n",
        "plt.text(\n",
        "    df_embedding.w1[3], df_embedding.w2[3], df_embedding.token[3],\n",
        "    horizontalalignment='left',\n",
        "    size='medium',\n",
        "    weight='semibold');"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb8409a0-453a-459a-8475-ecafbed5d910",
      "metadata": {
        "id": "bb8409a0-453a-459a-8475-ecafbed5d910"
      },
      "source": [
        "We see that the embedding values for *Troll 2* and *Gymkata* are relatively different. So let's train the model and see if they become more similar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "e2862797-d87e-434f-9758-698cccb51d66",
      "metadata": {
        "id": "e2862797-d87e-434f-9758-698cccb51d66"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "\n",
            "  | Name             | Type             | Params | Mode \n",
            "--------------------------------------------------------------\n",
            "0 | input_to_hidden  | Linear           | 8      | train\n",
            "1 | hidden_to_output | Linear           | 8      | train\n",
            "2 | loss             | CrossEntropyLoss | 0      | train\n",
            "--------------------------------------------------------------\n",
            "16        Trainable params\n",
            "0         Non-trainable params\n",
            "16        Total params\n",
            "0.000     Total estimated model params size (MB)\n",
            "3         Modules in train mode\n",
            "0         Modules in eval mode\n",
            "c:\\Users\\SÃ©bastien\\Documents\\data_science\\machine_learning\\statsquest_neural_networks\\.env\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "c:\\Users\\SÃ©bastien\\Documents\\data_science\\machine_learning\\statsquest_neural_networks\\.env\\Lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:310: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ab07a8af50d34299929740bf60c42e6b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
          ]
        }
      ],
      "source": [
        "trainer = L.Trainer(max_epochs=100)\n",
        "trainer.fit(modelLinear, train_dataloaders=dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "50ba39de-2c04-4f78-b619-c673c328beec",
      "metadata": {
        "id": "50ba39de-2c04-4f78-b619-c673c328beec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After optimization (nn.Linear), the parameters are:\n",
            "input_to_hidden.weight tensor([[ 2.5104, -1.0177, -1.9742,  2.4355],\n",
            "        [-0.0688,  2.4824, -1.8190, -0.2228]])\n",
            "hidden_to_output.weight tensor([[-0.3022, -1.0102],\n",
            "        [ 3.2008, -0.3850],\n",
            "        [-0.6693,  2.1814],\n",
            "        [-2.6841, -2.9578]])\n"
          ]
        }
      ],
      "source": [
        "print(\"After optimization (nn.Linear), the parameters are:\")\n",
        "for name, param in modelLinear.named_parameters():\n",
        "    print(name, param.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "9b7cab77-be81-42a4-ad47-90cde6c8fccc",
      "metadata": {
        "id": "9b7cab77-be81-42a4-ad47-90cde6c8fccc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding vector after optimization:\n",
            "         w1        w2    token   input\n",
            "0  2.510447 -0.068821   Troll2  input1\n",
            "1 -1.017650  2.482441       is  input2\n",
            "2 -1.974159 -1.818951    great  input3\n",
            "3  2.435523 -0.222807  Gymkata  input4\n"
          ]
        }
      ],
      "source": [
        "data_embedding_opt = {\n",
        "    \"w1\": modelLinear.input_to_hidden.weight.detach()[0].numpy(),\n",
        "    \"w2\": modelLinear.input_to_hidden.weight.detach()[1].numpy(),\n",
        "    \"token\": [\"Troll2\", \"is\", \"great\", \"Gymkata\"],\n",
        "    \"input\": [\"input1\", \"input2\", \"input3\", \"input4\"]\n",
        "}\n",
        "\n",
        "df_embedding_opt = pd.DataFrame(data_embedding_opt)\n",
        "\n",
        "print(\"Embedding vector after optimization:\")\n",
        "print(df_embedding_opt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "353ec7e8-7a0e-4e3c-8e65-88bcf6e1c4d9",
      "metadata": {
        "id": "353ec7e8-7a0e-4e3c-8e65-88bcf6e1c4d9"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(4,4))\n",
        "sns.scatterplot(data=df_embedding_opt, x=\"w1\", y=\"w2\")\n",
        "\n",
        "# Troll 2\n",
        "plt.text(\n",
        "    df_embedding_opt.w1[0]-.2, df_embedding_opt.w2[0]-.3, df_embedding_opt.token[0],\n",
        "    horizontalalignment='left',\n",
        "    size='medium',\n",
        "    weight='semibold')\n",
        "\n",
        "# is\n",
        "plt.text(\n",
        "    df_embedding_opt.w1[1], df_embedding_opt.w2[1], df_embedding_opt.token[1],\n",
        "    horizontalalignment='left',\n",
        "    size='medium',\n",
        "    weight='semibold')\n",
        "\n",
        "# great\n",
        "plt.text(\n",
        "    df_embedding_opt.w1[2], df_embedding_opt.w2[2], df_embedding_opt.token[2],\n",
        "    horizontalalignment='left',\n",
        "    size='medium',\n",
        "    weight='semibold')\n",
        "\n",
        "# Gymkata\n",
        "plt.text(\n",
        "    df_embedding_opt.w1[3]-.3, df_embedding_opt.w2[3]+.2, df_embedding_opt.token[3],\n",
        "    horizontalalignment='left',\n",
        "    size='medium',\n",
        "    weight='semibold');"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94ad130f-5e94-4615-9916-0601eda24970",
      "metadata": {
        "id": "94ad130f-5e94-4615-9916-0601eda24970"
      },
      "source": [
        "And, after training the model, we see that the embedding values for *Troll 2* and *Gymkata* are more similar than before.\n",
        "\n",
        "Lastly, we can verify that each token in the vacabulary correctly predicts the token that follows it by running the **one-hot-encoded** input values for each token through the neural network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "2135f619-f564-4270-b984-23bc189b3769",
      "metadata": {
        "id": "2135f619-f564-4270-b984-23bc189b3769"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction for 'Troll 2': tensor([[0., 1., 0., 0.]], grad_fn=<RoundBackward0>)\n",
            "Prediction for 'is': tensor([[0., 0., 1., 0.]], grad_fn=<RoundBackward0>)\n",
            "Prediction for 'great': tensor([[0., 0., 0., 1.]], grad_fn=<RoundBackward0>)\n",
            "Prediction for 'Gymkata': tensor([[0., 1., 0., 0.]], grad_fn=<RoundBackward0>)\n"
          ]
        }
      ],
      "source": [
        "softmax = nn.Softmax(dim=1) # dim=0 applies softmax to rows, dim=1 applies softmax to columns\n",
        "\n",
        "# Unlike the modelFromScratch model, nn.Linear produces a 2D tensor with shape (1, 4),\n",
        "# preserving the batch dimension: [[val1, val2, val3, val4]].\n",
        "# Since the classes are arranged across the columns (Dimension 1), we use dim=1 \n",
        "# to squash the values across the row so they sum to 1.\n",
        "\n",
        "print(\n",
        "    \"Prediction for 'Troll 2':\",\n",
        "    torch.round(\n",
        "        softmax(\n",
        "            modelLinear(\n",
        "                torch.tensor(\n",
        "                    [[1., 0., 0., 0.]])))))\n",
        "\n",
        "print(\n",
        "    \"Prediction for 'is':\",\n",
        "    torch.round(\n",
        "        softmax(\n",
        "            modelLinear(\n",
        "                torch.tensor(\n",
        "                    [[0., 1., 0., 0.]])))))\n",
        "\n",
        "print(\n",
        "    \"Prediction for 'great':\",\n",
        "    torch.round(\n",
        "        softmax(\n",
        "            modelLinear(\n",
        "                torch.tensor(\n",
        "                    [[0., 0., 1., 0.]])))))\n",
        "\n",
        "print(\n",
        "    \"Prediction for 'Gymkata':\",\n",
        "    torch.round(\n",
        "        softmax(\n",
        "            modelLinear(\n",
        "                torch.tensor(\n",
        "                    [[0., 0., 0., 1.]])))))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea2b8a06-ab36-441c-8963-f0b1d95fdff0",
      "metadata": {
        "id": "ea2b8a06-ab36-441c-8963-f0b1d95fdff0"
      },
      "source": [
        "## Use `nn.Embedding()` to load and use pre-trained Word Embeddings\n",
        "\n",
        "Now that we have created embeddings for each token in the vocabulary, we can store them in an `nn.Embedding()` object so that we can access them with the tokens, rather than the one-hot-encoded versions of the tokens. This makes them easily portable to other applications.\n",
        "\n",
        "First, let's just print out the embedding values that we created in modelLinear and that we want to add to an `nn.Embedding()` object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "f3dec6c7-2aa0-4adc-8096-cf25b7b35a0e",
      "metadata": {
        "id": "f3dec6c7-2aa0-4adc-8096-cf25b7b35a0e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 2.5104, -1.0177, -1.9742,  2.4355],\n",
              "        [-0.0688,  2.4824, -1.8190, -0.2228]], requires_grad=True)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "modelLinear.input_to_hidden.weight"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d619c92a-865e-424a-8463-46f78d5318e8",
      "metadata": {
        "id": "d619c92a-865e-424a-8463-46f78d5318e8"
      },
      "source": [
        "Now let's create an `nn.Embedding()` object and add those Embedding Values to it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "bf2a3942-0be2-4310-b05b-39de6fe379d4",
      "metadata": {
        "id": "bf2a3942-0be2-4310-b05b-39de6fe379d4"
      },
      "outputs": [],
      "source": [
        "# We have to transpose the original embedding values (from w1 and w2) for nn.Embedding()\n",
        "# and we do this with adding a '.T' to modelLinear.input_to_hidden.weight.T\n",
        "word_embeddings = nn.Embedding.from_pretrained(modelLinear.input_to_hidden.weight.T)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7f1a48b-76b8-4f2e-be7c-938a9b8e7691",
      "metadata": {
        "id": "c7f1a48b-76b8-4f2e-be7c-938a9b8e7691"
      },
      "source": [
        "Now let's print out the weights to make sure they are what we expect them to be."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "5b646de6-0027-447c-9938-f69bcf53f3de",
      "metadata": {
        "id": "5b646de6-0027-447c-9938-f69bcf53f3de"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 2.5104, -0.0688],\n",
              "        [-1.0177,  2.4824],\n",
              "        [-1.9742, -1.8190],\n",
              "        [ 2.4355, -0.2228]])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_embeddings.weight"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd40ef57-32ec-4078-bf78-241c93bfc646",
      "metadata": {
        "id": "dd40ef57-32ec-4078-bf78-241c93bfc646"
      },
      "source": [
        "Now we can access the embeddings for each token directly with an index between 0 and 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "568cee2b-e7fc-4874-8a2b-d2344a682db9",
      "metadata": {
        "id": "568cee2b-e7fc-4874-8a2b-d2344a682db9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 2.5104, -0.0688])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_embeddings(torch.tensor(0))  # retrieve the embedding values for 'Troll2'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cdeca04-4187-418e-9f4e-04575165765a",
      "metadata": {
        "id": "1cdeca04-4187-418e-9f4e-04575165765a"
      },
      "source": [
        "We can also create a dictionary and access the embedding values with words or tokens instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "8b001059-a593-45e0-b4b4-13f47901863f",
      "metadata": {
        "id": "8b001059-a593-45e0-b4b4-13f47901863f"
      },
      "outputs": [],
      "source": [
        "vocab = {\n",
        "    'Troll2': 0,\n",
        "    'is': 1,\n",
        "    'great': 2,\n",
        "    'Gymkata': 3}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "98be858c-51cc-4845-9b60-57eec729939b",
      "metadata": {
        "id": "98be858c-51cc-4845-9b60-57eec729939b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding for 'Troll2':\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([ 2.5104, -0.0688])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Embedding for 'Troll2':\")\n",
        "word_embeddings(\n",
        "    torch.tensor(\n",
        "        vocab['Troll2']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "52a2cde0-c21f-4e4f-836b-9a5799269cff",
      "metadata": {
        "id": "52a2cde0-c21f-4e4f-836b-9a5799269cff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding for 'Gymkata':\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([ 2.4355, -0.2228])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Embedding for 'Gymkata':\")\n",
        "word_embeddings(\n",
        "    torch.tensor(\n",
        "        vocab['Gymkata']))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c6ee2b3-4ca1-42a1-9fae-93dcc706c1df",
      "metadata": {
        "id": "8c6ee2b3-4ca1-42a1-9fae-93dcc706c1df"
      },
      "source": [
        "## Build and train a Word Embedding Unit using `nn.Embedding()` and `nn.Linear()`\n",
        "\n",
        "Although less commonly done, we can replace `nn.Linear()` from the inputs to the activation functions with `nn.Embedding()` and train the embeddings directly in the lookup table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "5e5e6033-ef32-46c2-ab36-25f6c251b09f",
      "metadata": {
        "id": "5e5e6033-ef32-46c2-ab36-25f6c251b09f"
      },
      "outputs": [],
      "source": [
        "class WordEmbeddingWithEmbedding(L.LightningModule):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        L.seed_everything(seed=42)\n",
        "\n",
        "        self.embed = nn.Embedding(4, 2)  # 4 = number of words in the vocabulary,\n",
        "                                         # 2 = numbers per embedding\n",
        "        self.hidden_to_output = nn.Linear(2, 4, bias=False)\n",
        "\n",
        "        self.loss = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "        hidden = self.embed(input[0])\n",
        "        output_values = self.hidden_to_output(hidden)\n",
        "\n",
        "        return(output_values)\n",
        "\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return Adam(self.parameters(), lr=0.1)\n",
        "\n",
        "\n",
        "    def training_step(self, batch):\n",
        "        input_i, label_i = batch\n",
        "        output_i = self.forward(input_i[0])\n",
        "        loss = self.loss(output_i, label_i[0])\n",
        "\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "a516b61c-6502-443d-9711-c79d8a0e7644",
      "metadata": {
        "id": "a516b61c-6502-443d-9711-c79d8a0e7644"
      },
      "outputs": [],
      "source": [
        "# nn.Embedding() applies one-hot-encoding to the input for us, so\n",
        "# the data that we use for training will look different from before.\n",
        "inputsForEmbed = torch.tensor([[0], [1], [2], [3]])  # Troll2 = 0, is = 1, great = 2, Gymkata = 3\n",
        "labels = torch.tensor([[0., 1., 0., 0.], [0., 0., 1., 0.], [0., 0., 0., 1.], [0., 1., 0., 0.]])\n",
        "\n",
        "datasetForEmbed = TensorDataset(inputsForEmbed, labels)\n",
        "dataloaderForEmbed = DataLoader(datasetForEmbed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "715a2df0-682d-4a4d-b8c4-cbc65cbf0288",
      "metadata": {
        "id": "715a2df0-682d-4a4d-b8c4-cbc65cbf0288"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Seed set to 42\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before optimization, the parameters are:\n",
            "embed.weight tensor([[ 0.3367,  0.1288],\n",
            "        [ 0.2345,  0.2303],\n",
            "        [-1.1229, -0.1863],\n",
            "        [ 2.2082, -0.6380]])\n",
            "hidden_to_output.weight tensor([[ 0.5451,  0.1045],\n",
            "        [-0.3301,  0.1802],\n",
            "        [-0.3258, -0.0829],\n",
            "        [-0.2872,  0.4691]])\n"
          ]
        }
      ],
      "source": [
        "modelEmbed = WordEmbeddingWithEmbedding()\n",
        "\n",
        "print(\"Before optimization, the parameters are:\")\n",
        "for name, param in modelEmbed.named_parameters():\n",
        "    print(name, param.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "e4b6d167-10a6-4aab-96d6-3bb120a913a5",
      "metadata": {
        "id": "e4b6d167-10a6-4aab-96d6-3bb120a913a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[np.float32(0.33669037),\n",
              " np.float32(0.23446237),\n",
              " np.float32(-1.1228564),\n",
              " np.float32(2.2082014)]"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weights = modelEmbed.embed.weight.detach().numpy()\n",
        "w1 = [weights[0][0], weights[1][0], weights[2][0], weights[3][0]]\n",
        "w1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "1b5572e2-6508-49f9-bcf8-3f644f7ddb1c",
      "metadata": {
        "id": "1b5572e2-6508-49f9-bcf8-3f644f7ddb1c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[np.float32(0.1288094),\n",
              " np.float32(0.23033303),\n",
              " np.float32(-0.18632829),\n",
              " np.float32(-0.63799703)]"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w2 = [weights[0][1], weights[1][1], weights[2][1], weights[3][1]]\n",
        "w2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "28abf23a-3704-4e0f-8398-63173788ea9c",
      "metadata": {
        "id": "28abf23a-3704-4e0f-8398-63173788ea9c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>w1</th>\n",
              "      <th>w2</th>\n",
              "      <th>token</th>\n",
              "      <th>input</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.336690</td>\n",
              "      <td>0.128809</td>\n",
              "      <td>Troll2</td>\n",
              "      <td>input1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.234462</td>\n",
              "      <td>0.230333</td>\n",
              "      <td>is</td>\n",
              "      <td>input2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.122856</td>\n",
              "      <td>-0.186328</td>\n",
              "      <td>great</td>\n",
              "      <td>input3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.208201</td>\n",
              "      <td>-0.637997</td>\n",
              "      <td>Gymkata</td>\n",
              "      <td>input4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         w1        w2    token   input\n",
              "0  0.336690  0.128809   Troll2  input1\n",
              "1  0.234462  0.230333       is  input2\n",
              "2 -1.122856 -0.186328    great  input3\n",
              "3  2.208201 -0.637997  Gymkata  input4"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = {\n",
        "    \"w1\": w1,\n",
        "    \"w2\": w2,\n",
        "    \"token\": [\"Troll2\", \"is\", \"great\", \"Gymkata\"],\n",
        "    \"input\": [\"input1\", \"input2\", \"input3\", \"input4\"]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "d65ca2b2-4258-4625-8aac-d88fb107d15d",
      "metadata": {
        "id": "d65ca2b2-4258-4625-8aac-d88fb107d15d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(2.2082014083862305, -0.637997031211853, 'Gymkata')"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(4,4))\n",
        "sns.scatterplot(data=df, x=\"w1\", y=\"w2\")\n",
        "\n",
        "plt.text(\n",
        "    df.w1[0], df.w2[0], df.token[0],\n",
        "    horizontalalignment='left',\n",
        "    size='medium',\n",
        "    color='black',\n",
        "    weight='semibold') # Troll 2\n",
        "\n",
        "plt.text(\n",
        "    df.w1[1], df.w2[1], df.token[1],\n",
        "    horizontalalignment='left',\n",
        "    size='medium',\n",
        "    color='black',\n",
        "    weight='semibold') # is\n",
        "plt.text(\n",
        "    df.w1[2], df.w2[2], df.token[2],\n",
        "    horizontalalignment='left',\n",
        "    size='medium',\n",
        "    color='black',\n",
        "    weight='semibold') # great\n",
        "plt.text(\n",
        "    df.w1[3], df.w2[3], df.token[3],\n",
        "    horizontalalignment='left',\n",
        "    size='medium',\n",
        "    color='black',\n",
        "    weight='semibold') # Gymkata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "1be779d5-5fdf-4363-bf49-ae41cc51eb98",
      "metadata": {
        "id": "1be779d5-5fdf-4363-bf49-ae41cc51eb98"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "\n",
            "  | Name             | Type             | Params | Mode \n",
            "--------------------------------------------------------------\n",
            "0 | embed            | Embedding        | 8      | train\n",
            "1 | hidden_to_output | Linear           | 8      | train\n",
            "2 | loss             | CrossEntropyLoss | 0      | train\n",
            "--------------------------------------------------------------\n",
            "16        Trainable params\n",
            "0         Non-trainable params\n",
            "16        Total params\n",
            "0.000     Total estimated model params size (MB)\n",
            "3         Modules in train mode\n",
            "0         Modules in eval mode\n",
            "c:\\Users\\SÃ©bastien\\Documents\\data_science\\machine_learning\\statsquest_neural_networks\\.env\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "c:\\Users\\SÃ©bastien\\Documents\\data_science\\machine_learning\\statsquest_neural_networks\\.env\\Lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:310: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5adf40b0497a461986a5561decc031ea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
          ]
        }
      ],
      "source": [
        "trainer = L.Trainer(max_epochs=100)\n",
        "trainer.fit(modelEmbed, train_dataloaders=dataloaderForEmbed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "a29ea237-abc9-4bc0-9049-b1af073e2cbc",
      "metadata": {
        "id": "a29ea237-abc9-4bc0-9049-b1af073e2cbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After optimization, the parameters are:\n",
            "embed.weight tensor([[ 1.7255,  2.6477],\n",
            "        [ 0.9756, -2.5702],\n",
            "        [-3.5512, -0.1337],\n",
            "        [ 3.3123,  0.9554]])\n",
            "hidden_to_output.weight tensor([[-6.0445e-01,  1.6247e-01],\n",
            "        [ 1.6389e+00,  1.7619e+00],\n",
            "        [ 1.6950e-03, -2.8041e+00],\n",
            "        [-2.8600e+00,  7.4534e-02]])\n"
          ]
        }
      ],
      "source": [
        "print(\"After optimization, the parameters are:\")\n",
        "for name, param in modelEmbed.named_parameters():\n",
        "    print(name, param.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "71fe1035-b0e6-47f8-93bd-69b60a30e821",
      "metadata": {
        "id": "71fe1035-b0e6-47f8-93bd-69b60a30e821"
      },
      "outputs": [],
      "source": [
        "weights = modelEmbed.embed.weight.detach().numpy()\n",
        "w1 = [weights[0][0], weights[1][0], weights[2][0], weights[3][0]]\n",
        "w2 = [weights[0][1], weights[1][1], weights[2][1], weights[3][1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "756b2c0b-16a6-40a1-b0a2-a177e0e1e597",
      "metadata": {
        "id": "756b2c0b-16a6-40a1-b0a2-a177e0e1e597"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>w1</th>\n",
              "      <th>w2</th>\n",
              "      <th>token</th>\n",
              "      <th>input</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.725517</td>\n",
              "      <td>2.647727</td>\n",
              "      <td>Troll2</td>\n",
              "      <td>input1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.975586</td>\n",
              "      <td>-2.570216</td>\n",
              "      <td>is</td>\n",
              "      <td>input2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-3.551210</td>\n",
              "      <td>-0.133742</td>\n",
              "      <td>great</td>\n",
              "      <td>input3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.312256</td>\n",
              "      <td>0.955405</td>\n",
              "      <td>Gymkata</td>\n",
              "      <td>input4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         w1        w2    token   input\n",
              "0  1.725517  2.647727   Troll2  input1\n",
              "1  0.975586 -2.570216       is  input2\n",
              "2 -3.551210 -0.133742    great  input3\n",
              "3  3.312256  0.955405  Gymkata  input4"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = {\n",
        "    \"w1\": w1,\n",
        "    \"w2\": w2,\n",
        "    \"token\": [\"Troll2\", \"is\", \"great\", \"Gymkata\"],\n",
        "    \"input\": [\"input1\", \"input2\", \"input3\", \"input4\"]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "869acfd0-6bc0-4abb-bc80-b1ea8f1b8fca",
      "metadata": {
        "id": "869acfd0-6bc0-4abb-bc80-b1ea8f1b8fca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(3.012256383895874, 1.155404806137085, 'Gymkata')"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(4,4))\n",
        "sns.scatterplot(data=df, x=\"w1\", y=\"w2\")\n",
        "\n",
        "plt.text(\n",
        "    df.w1[0]-0.2, df.w2[0]-0.3, df.token[0],\n",
        "    horizontalalignment='left',\n",
        "    size='medium',\n",
        "    weight='semibold') # Troll 2\n",
        "plt.text(\n",
        "    df.w1[1], df.w2[1], df.token[1],\n",
        "    horizontalalignment='left',\n",
        "    size='medium',\n",
        "    weight='semibold') # is\n",
        "plt.text(\n",
        "    df.w1[2], df.w2[2], df.token[2],\n",
        "    horizontalalignment='left',\n",
        "    size='medium',\n",
        "    weight='semibold') # great\n",
        "plt.text(\n",
        "    df.w1[3]-0.3, df.w2[3]+0.2, df.token[3],\n",
        "    horizontalalignment='left',\n",
        "    size='medium',\n",
        "    weight='semibold') # Gymkata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86755105-b05e-49f7-8a35-88198218d04d",
      "metadata": {
        "id": "86755105-b05e-49f7-8a35-88198218d04d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0., 1., 0., 0.])\n",
            "tensor([0., 0., 1., 0.])\n",
            "tensor([0., 0., 0., 1.])\n",
            "tensor([0., 1., 0., 0.])\n"
          ]
        }
      ],
      "source": [
        "## Let's see what the model predicts\n",
        "softmax = nn.Softmax(dim=0) ## dim=0 applies softmax to rows, dim=1 applies softmax to columns\n",
        "\n",
        "print(torch.round(softmax(modelEmbed(torch.tensor([0])).detach()), decimals=2)) # print the predictions for \"Troll2\"\n",
        "print(torch.round(softmax(modelEmbed(torch.tensor([1])).detach()), decimals=2)) # print the predictions for \"is\"\n",
        "print(torch.round(softmax(modelEmbed(torch.tensor([2])).detach()), decimals=2)) # print the predictions for \"great\"\n",
        "print(torch.round(softmax(modelEmbed(torch.tensor([3])).detach()), decimals=2)) # print the predictions for \"Gymkata\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
